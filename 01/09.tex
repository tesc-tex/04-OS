\subsection{%
  Лекция \texttt{24.??.??}.%
}

\subheader{Взаимодействие процессов}

Взаимодействие процессов бывает внешним и внутренним. Под внешним
взаимодействием понимается возможность процессов обменяться управлением или
данными. Внешнее взаимодействие инициируется нами, а значит мы точно знаем, чего
нам хочется. В Linux внешнее взаимодействие по данным можно осуществить,
например, с помощью pipe, передав вывод одного процесса на вход другому. Внешнее
взаимодействие по управлению осуществляется через сигналы: один процесс может
послать сигнал другому процессу, а тот, после обработки сигнала, изменит свое
поведение. В целом, со внешним взаимодействием нет особых проблем: ОС нужно лишь
осуществлять буферизацию, т.к. когда один процесс посылает другому сигнал, то
адресат может быть не готов его принять. В этом случае необходимо составить
очередь и, когда процессу будет предоставлено время исполнения, передать ему
сигналы из этой очереди.

Значительно более сложной задачей является задача вынужденного взаимодействия,
когда процессы начинают конкурировать за неразделяемый ресурс. Самый простой
пример, который здесь можно привести это пример с принтером: один процесс
отправил часть данных для печати в принтер, но потом его вытеснил другой
процесс, который тоже отправил часть своих данных в принтер. В итоге принтер
распечатает не то, что мы хотели, если вообще что-то распечатает. Более
неприятными являются ситуации, в которых неразделяемый ресурс это, например,
какие-то структуры файловой системы. В такой ситуации конкуренция двух процессов
может привести к потере данных во всей файловой системе. Таким образом возникает
проблема, которая получила название взаимоисключение, т.е. мы должны обеспечить
взаимоисключение доступа процессов к какому-либо неразделяемому ресурсу.

Мы не можем при рождении процесса блокировать все ресурсы, которые потенциально
могут быть им использованы~--- в таком случае, нам, чтобы, например, поработать
с принтером, придется закрыть все приложения, которые умеют с ним работать,
кроме одного, которое на самом деле хочет что-то напечатать. Однако нам и не
нужно такое жесткое решение: достаточно блокировать ресурс только на то время,
когда приложение его действительно использует. Из исходного кода приложения
четко можно выделить часть, которая непосредственно работает с неразделяемым
ресурсом. Такую часть стали называть критической секцией кода относительно этого
неразделяемого ресурса. Важно помнить, что одно приложение может
взаимодействовать с несколькими неразделяемыми ресурсами, и, как следствие,
иметь несколько критических секций относительно разных ресурсов. Более того эти
секции могут даже пересекаться. Таким образом задача взаимоисключения сводится к
тому, что мы должны обеспечить невозможность двух и более процессов одновременно
находится в критических секциях относительно одного и того же неразделяемого
ресурса.

Эту задачу можно попытаться решить следующим образом: в код каждого процесса
перед входом в критическую секцию и после выхода из нее необходимо добавить так
называемые пролог и эпилог. В прологе процесс сообщает ОС о том, что входит в
критическую секцию и собирается использовать неразделяемый ресурс. ОС либо
позволяет ему это сделать, либо приостанавливает его, т.к. ресурс в данный
момент занят. В эпилоге процесс сообщает о том, что он вышел из критической
секции и больше не нуждается в неразделяемом ресурсе. Однако не все так просто:
помимо взаимоисключения нам также необходимо обеспечивать прогресс. Под
прогрессом мы будем понимать невозможность ситуации, при которой процесс не
может использовать свободный желаемый ресурс. Но и это еще не все. Помимо этих
двух требований мы также должны обеспечивать отсутствие голодания: например,
пусть есть три процесса. Если два из них по очереди используют ресурс, а третий
все время ждет, то говорят, что этот процесс \quote{голодает}. Мы должны не
допускать подобных ситуаций. Четвертным требованием, выдвигаемым к механизмам
взаимодействия процессов, является обеспечение отсутствия тупиков. Самым простым
вариантом тупика является ситуация, при которой два процесса заблокировали свои
ресурсы и нуждаются в ресурсах друг друга, из-за чего не могут продолжить
исполнение и просто бесконечно долго ждут. Однако могут быть и круговые тупики,
в которых процессы по кругу бесконечно ждут друг друга.

Итого, требования, выдвигаемые к механизму взаимодействия процессов, выглядят
так:

\begin{enumerate}
\item
  Взаимоисключение.

\item
  Обеспечение прогресса.

\item
  Отсутствие голодания.

\item
  Отсутствие тупиков.
\end{enumerate}

Первый подход, который появился, это решить данную проблему на аппаратном
уровне. Сложности, которые у нас возникают, обусловлены вытесняющей
многозадачностью, однако мы не можем от нее отказаться, т.к. она обеспечивает
эффективность, справедливость и т.д. Однако мы может сделать так, чтобы процесс
в своем прологе посылал ОС сигнал, благодаря которому ОС на аппаратном уровне
блокировала бы прерывания этого процесса. А по завершении критической секции, в
эпилоге, процесс бы посылал другой сигнал, и ОС отменяла бы блокировку
прерываний. Это простое, но с тем довольно опасное решение: во-первых, мы
полностью ломаем работу планировщика~--- как только процессу потребовался
неразделяемый ресурс, мы тут же вынуждены отменить текущее планирование и
позволить процессу пользоваться этим ресурсом столько, сколько ему требуется.
Во-вторых, если в критической секции произойдет ошибка и процесс не дойдет до
эпилога, то блокировка прерываний останется, и нельзя будет ничего сделать с
таким процессом.

Такой подход получил название однопрограммного режима, и несмотря на свою
опасность в большинстве ОС есть фрагменты кода, где он используется. Например,
он используется при диспетчеризации (переключении) процессов, т.к. она должна
быть атомарной, а если во время смены регистрового контекста произойдет
прерывание, то мы потеряем целостность данных. Однако это код ядра, и он хорошо
протестирован, но для всего остального аппаратное решение не годится, и надо
искать программное решение. В чем сложность программного решения? Сложность
заключается в том, что процессы изолированны, а значит не могут сами
\quote{договориться} об очередности использования ресурса. Для этого их
необходимо использовать структуры данных внутри ОС: сначала один процесс напишет
о себе какую-то информацию, а затем другой процесс прочитает ее. Такие
программные решения получили название алгоритмов взаимоисключения. Далее мы
рассмотрим некоторые из них. Ниже будет использоваться псевдокод, который стоит
воспринимать лишь как общую идею алгоритма, а не его конкретную реализацию.

\subsubheader{I.}{Зам\'oк}

\begin{ccode}
  shared int lock = 0;

  P_i() {
    ... // some code before

    while (lock) {}; // prologue |\label{lst:lock-1}|
    lock = 1; |\label{lst:lock-2}|

    ... // critical section

    lock = 0; // epilogue

    ... // some code after
  }
\end{ccode}

Здесь под \cinline{shared} подразумевается то, что к этой переменной имеют
доступ несколько процессов (в реальности это реализовано через системные
вызовы). Под \cinline{P_i} имеется в виду \(i\)-ый процесс, причем количество
процессов может быть любым~--- алгоритм от этого не зависит.

В чем может быть проблема такого алгоритма? Т.к. у нас вытесняющее планирование,
то в любой момент может произойти прерывание. Допустим, что процесс \(p_0\) был
прерван после выполнения строчки~\ref{lst:lock-1}, но перед выполнением
строчки~\ref{lst:lock-2}. После этого процесс \(p_1\) также решил зайти в
критическую секцию и успешно это сделал (так как замок был \quote{открыт}).
Затем \(p_1\) был прерван в процессе выполнения своей критической секции, и
управление вернулось к \(p_0\). Он начал свое исполнение со
строчки~\ref{lst:lock-2}, закрыл замок (который, впрочем, уже был закрыт) и
также вошел в критическую секцию. Таким образом нарушилось условие
взаимоисключения.

\subsubheader{II.}{Строгое чередование}

\begin{ccode}
  shared int turn = 0;

  P_i() {
    ... // some code before

    while (turn != i) {}; // prologue 

    ... // critical section

    turn = 1 - i; // epilogue

    ... // some code after
  }
\end{ccode}

Данный код написан для двух процессов (\(i \in \set{0, 1}\)), однако он может
быть легко расширен и на большее число процессов. Теперь, т.к. пролог и эпилог
состоят из одной команды, то не будет проблем с прерываниями и условие
взаимоисключения будет соблюдено. Однако возникает проблема, связанная с
условием прогресса: пусть процесс \(p_0\) выполнил свою критическую секцию и
передал \quote{ход} процессу \(p_1\). Допустим, что процесс \(p_1\) в это время
спит или не хочет использовать этот ресурс. Далее процессу \(p_0\) вновь
потребовался неразделяемый ресурс, однако он не может получить его, т.к. ход ему
может передать только \(p_1\), который не собирается этого делать. В итоге мы
получаем ситуацию, при которой ресурс свободен, однако в силу нашего алгоритма,
никто его не использует.

\subsubheader{III.}{Флаги готовности}

\begin{ccode}
  shared int ready[2] = { 0, 0 };

  P_i() {
    ... // some code before

    ready[i] = 1; // prologue |\label{lst:flags-1}|
    while (ready[1 - i]) {}; |\label{lst:flags-2}|

    ... // critical section

    ready[i] = 0; // epilogue

    ... // some code after
  }
\end{ccode}

Вместо того, чтобы делать одну переменную для всех процессов, появилась идея
делать по одной переменной на каждый процесс. В коде выше рассматривается
ситуация для \(n = 2\) процессов, однако алгоритм может быть масштабирован и на
большее число процессов. Проблема данного подхода заключается в потенциальной
возможности тупика. Пусть \(p_0\) выполнил строчку~\ref{lst:flags-1} и тут же
произошло прерывание. После этого \(p_1\) выполнил свою
строчку~\ref{lst:flags-1} и встал в ожидание на строчке~\ref{lst:flags-2}, т.к.
\(p_0\) уже успел поднять свой флаг готовности. После этого произошло еще одно
прерывание и управление вернулось к \(p_0\). Он тоже встал в ожидание на
строчке~\ref{lst:flags-2}, т.к. \(p_1\) поднял свой флаг готовности. В итоге оба
процесса будут бесконечно друг друга ждать~--- нарушается условие прогресса и
условие отсутствия тупиков. Здесь стоит отметить, что если в предыдущем подходе
была возможность выхода из ожидания (процесс \(p_1\) мог когда-нибудь выполнить
свою критическую секцию и передать \quote{ход} обратно \(p_0\)), то здесь такой
возможности нет. Процессы будут ждать друг друга бесконечно и ни один из них так
и не выполнит свою критическую секцию.

\subsubheader{IV.}{Алгоритм Петерсона}

В этот момент появилась идея о том, что программного решения может и не
существовать. Люди стали пытаться доказать, что требуемый алгоритм нельзя
построить, однако этого не получилось сделать. Только в \(1981\)-ом году
появляется решение данной задачи, которое получает название по имени автора.

\begin{ccode}
  shared int ready[2] = { 0, 0 };
  shared int turn = 0;

  P_i() {
    ... // some code before

    ready[i] = 1; // prologue
    turn = 1 - i;
    while (ready[1 - i] && turn == 1 - i) {}; |\label{lst:peterson-1}|

    ... // critical section

    ready[i] = 0; // epilogue

    ... // some code after
  }
\end{ccode}

Этот алгоритм так же называется алгоритмом \quote{вежливого чередования}: в
прологе, после того как процесс заявляет о своем намерении использовать ресурс,
он передает \quote{ход} другому процессу и встает в ожидание до тех пор, пока
\quote{ход} в руках другого процесса и тот претендует на использование ресурса.
Данный алгоритм решает проблему взаимоисключения, обеспечивает прогресс и
отсутствие тупиков. Его проблема заключается в том, что если процессов не \(2\),
а больше, то они должны \quote{вежливо передавать ход} по кругу, а это долго.
Помимо этого условие в строчке~\ref{lst:peterson-1} станет не таким простым, и
на его вычисление потребуется время. Также проблема возникает, если рождается
новый процесс, претендующий на данный ресурс: его нужно как-то встроить в круг
уже существующих процессов. Итого данный алгоритм решает поставленную проблему,
но его накладные расходы могут оказаться слишком большими.

\subsubheader{V.}{Аппаратная поддержка взаимоисключений}

Т.к. найти эффективного программного решения не получилось, то люди вернулись к
идее об аппаратном решении проблемы. Как мы уже выяснили выше, полностью
переходить в однопрограммный режим это опасно, однако нам это и не нужно: нам
хотелось бы, чтобы (например) в алгоритме \quote{Зам\'oк} не происходило
прерываний между строчками~\ref{lst:lock-1} и \ref{lst:lock-2}. Для этого была
разработана специальная сложная инструкция процессора, которая проверяет
переменную, и, если она равна нулю, то возвращает \texttt{true} и одновременно с
этим (атомарно) устанавливает значение \(1\) в эту переменную. Если же
проверяемая переменная не равна нулю, то просто возвращается \texttt{false}.
Используя полученную инструкцию, можно слегка скорректировать код самого первого
алгоритма и получить следующее:

\begin{ccode}
  shared int lock = 0;

  P_i() {
    ... // some code before

    while (test_and_set(&lock)) {}; // prologue

    ... // critical section

    lock = 0; // epilogue

    ... // some code after
  }
\end{ccode}

То, что мы получили, называется мьютекс (mutex). Однако на самом деле мьютекс
это лишь частный случай другой, более сложной конструкции, которая называется
семафор. Дело в том, что не всегда ресурс бывает только в двух состояниях
(\quote{занят} или \quote{свободен}), иногда ресурс может быть частично
занят и требуется знать, на сколько именно он занят. Для этого и существует идея
семафоров, предложенная Дейкстрой еще в \(1965\)-ом году.
