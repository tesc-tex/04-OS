\subsection{%
  Лекция \texttt{24.??.??}.%
}

Сначала сформулируем некоторые требования, которыми мы выдвигаем к нашему
решению в области планирования процессов:

\begin{enumerate}
\item
  Поддержка внешнего управления приоритетами.

  У пользователя должна быть возможность указать более приоритетный процесс. 

\item
  Эффективное использование ресурсов.

  Здесь речь идет не только про ресурс центрального процессора, но и про
  оперативную память и другие ресурсы. Основное требование заключается в том,
  что если есть процессы, которые готовы исполняться, то они должны исполняться,
  и ЦП не должен простаивать. Также нужно, чтобы процессы как можно быстрее
  покидали оперативную память, чтобы освободить ее для других процессов. Помимо
  этого необходимо минимизировать накладные расходы. Например, на переключение
  между пользовательским режимом и режимом ядра, на переключение между
  процессами и т.д. К этому пункту также можно отнести эффективное использование
  кэша процессора.

\item
  Минимальные накладные расходы.

  Необходимо сделать так, чтобы сам алгоритм принятия решения об упорядочивании
  очереди не затрачивал слишком много ресурсов. Причем здесь необходимо помнить
  о том, что зачастую сам алгоритм выбора довольно быстрый и не требует много
  ресурсов, однако ему для работы требуются некоторые заранее собранные данные
  о процессах, некоторые предпосчитанные значения, и вот их вычисление может
  быть достаточно ресурсозатратным. Также как обычно не стоит забывать о том,
  что ресурсом является не только процессорное время, но и, например,
  оперативная память: алгоритм планирования, требующий слишком много памяти нас
  вряд ли будет устраивать.

\item
  Минимальные риски возникновения тупиков.

  Подробнее про тупики мы поговорим на следующих лекциях, сейчас рассмотрим лишь
  небольшой пример. Пусть у нас есть процесс \(p_1\), который сейчас использует
  ресурс \(R\). Спустя некоторое время более приоритетный процесс \(p_0\) тоже
  начинает требовать ресурс \(R\). Возникает проблема: процесс \(p_0\) не может
  выполняться, т.к. ему нужен ресурс \(R\). Отобрать этот ресурс у \(p_1\) мы не
  можем: например, ресурс \(R\) это принтер и процесс \(p_1\) уже начал на нем
  что-то печатать. В таком случае попытка отобрать ресурс может привести к
  потере целостности данных. Позволить процессу \(p_1\) завершить использование
  ресурса \(R\) мы также не можем: в таком случае мы нарушим наши же правила о
  приоритетности процессов. Так и возникает тупик: оба процесса не могут
  выполняться и просто бесконечно ждут.
\end{enumerate}

Для удовлетворения первого требования хорошо подойдут многоуровневые очереди,
которые мы уже рассмотрели. Для второго требования хорошо подойдет алгоритм SJF,
а также адаптируемые кванты непрерывного выполнения (чтобы минимизировать
различные переключения). Также для того, чтобы попадать в кэш, хорошо было бы
иметь раздельные очереди к разным ядрам (но при этом должна быть возможность
переходить между ними). Для выполнения третьего пункта нужно пользоваться по
возможности целочисленной арифметикой, а также использовать алгоритмы за
\(O(n)\) в худшем случае (а лучше что-то побыстрее). Также мы хотим, чтобы
структуры данных используемые в алгоритме, занимали разумное количество памяти.
Частичным решением для требования четвертого пункта является гарантированное
планирование: если все процессы будут получать примерно поровну процессорного
времени, то шанс возникновения тупиков уменьшится \ar{а почему?}.

\subheader{Планирование в Windows}

Понятное дело, что нельзя говорить просто Windows~--- нужно указывать версию,
однако т.к. Windows это проприетарная система, то мы можем лишь полагаться на 
открытую документацию (и на некоторое reverse engineering исследования).
Вдобавок к этому, будем считать, что общие концепции планирования не сильно
различаются от версии к версии.

Планирование в Windows основывается на идее многоуровневых очередей: их \(32\)
штуки, и чем больше номер очереди, тем приоритетнее процесс. Если в рамках одной
очереди есть несколько процессов, то они переключаются между собой при помощи
Round Robin'а. Все очереди разделены на два класса: c \(0\)-ой по \(15\)-ую это
динамические (переменные) приоритеты, а с \(16\)-ой по \(31\)-ую это процессы
реального времени. Особенность процессов реального времени заключается в том,
что ОС не меняет выданные им приоритеты. А вот у процессов с изначальными
приоритетами от \(0\) до \(15\) приоритет может меняться (решение об изменении
приоритета принимает ОС), однако он не может выйти за границы своего класса,
т.е. не может стать больше \(15\)-ти. Стоит сказать несколько слов про нулевую
очередь. Это очередь обнуления страниц: т.е. когда ОС не занята другими
процессами, то она занимается тем, что обнуляет страницы памяти, чтобы данные
уже завершившихся процессов не были получены новыми процессами.

Откуда пошло название процессы \quote{реального времени}? В прошлом была идея о
том, что можно создать механизм процессов реального времени, т.е. процессов для
которых время отклика не будет превышать некую заранее определенную константу.
Однако позже выяснилось, что осуществить эту идею в универсальной операционной
системе практически невозможно: это может быть связано, например, с тем, что
данные процесса находятся в файле подкачки, доступ к которому не очень быстрый,
или с непопаданием в кэш процессора и т.д. Таким образом реализовать ОС с
процессами реального времени можно, но для этого придется пожертвовать
оптимальностью использования ресурсов и универсальностью системы.

Для внешнего управления приоритетами существует \(6\) классов приоритетов
процессов, причем каждому классу соответствует номер очереди:

\begin{enumerate}
\item
  Процесс реального времени (realtime)~--- 24-ая очередь.

\item
  Высокий (high)~--- 13-ая очередь.

\item
  Выше нормального (above normal)~--- 10-ая очередь.

\item
  Нормальный (normal)~--- 8-ая очередь.

\item
  Ниже нормального (below normal)~--- 6-ая очередь.

\item
  Бездействующий (idle)~--- 4-ая очередь.
\end{enumerate}

Стоит отметить, что приоритет realtime может задать только администратор, у
обычного пользователя нет такой возможности. Здесь необходимо вспомнить о том,
что процесс это множество потоков, и у нас есть возможность отдавать приоритет
определенным потокам. Для этого существуют уровни насыщения:

\begin{enumerate}
\item
  Time critical (\(+15\)).

\item
  Highest (\(+2\)).

\item
  Above normal (\(+1\)).

\item
  Normal (\(\pm 0\)).

\item
  Below normal (\(-1\)).

\item
  Lowest (\(-2\)).

\item
  Idle (\(-15\)).
\end{enumerate}

Как это работает? Мы создаем процесс и задаем ему некоторый приоритет из первого
списка. Это базовое значение приоритета для всех его потоков. Далее с помощью
системного вызова можно задать некоторое насыщение для конкретного потока. Это
насыщение прибавляется к базовому приоритету и получается итоговое значение
приоритета для данного потока. Здесь важно помнить о том, что с помощью
насыщения потока нельзя перевести его из одного класса в другой, т.е. даже если
изначально приоритет был high, и мы использовали насыщение time critical, то
итоговый приоритет все равно будет равен \(15\). Аналогично насыщение idle
опустит realtime-приоритетный процесс лишь до \(16\)-ого уровня.

Мы поговорили про внешнее управление приоритетами, теперь можно поговорить и про
внутреннее. Операционная система может менять динамический приоритет в
зависимости от состояния процесса. \quote{Хорошим} для ОС является интерактивный
процесс: такой процесс часто уходит в ожидание ввода-вывода и не тратит много
процессорного времени. Это согласуется с идеей SJF, но как это реализовано?
Каждый процесс, который выходит из различных операций ввода-вывода, получает
временное повышение приоритета. Оно зависит от типа завершенной операции
ввода-вывода и версии ОС, например, для клавиатуры это может быть порядка
\(+6\) (но перейти из одного класса в другой таким образом все равно нельзя).
Также временное повышение приоритета получает процесс, который ждал освобождения
какого-либо ресурса. Это нужно для того, чтобы процесс побыстрее поработал с
этим ресурсом и освободил его, таким образом уменьшая вероятность возникновения
тупика. Помимо этого приоритет получает текущее активное (выбранное) окно.

Понятно, что все эти повышения приоритета не вечные, а временные. В Windows для
этого вводится некоторый квант времени, и если по истечении двух таких квантов
времени процесс самостоятельно не ушел в ожидание, то мы прерываем выполнение и
понижаем ему приоритет. Если, когда до него снова дошла очередь, он опять не
уложился в два кванта времени, то мы опять понижаем ему приоритет, и так далее,
пока его приоритет не вернется к изначальному значению.

Для борьбы с голоданием в Windows существует следующее решение: если какой-то
процесс не исполнялся в течении \(4\)-ех секунд, то ему на один квант дается
сразу \(15\)-ая очередь, после чего он возвращается в свою исходную очередь. Это
также помогает снизить риски, связанные с тупиками.

\subheader{Планирование в Linux. Планировщик \(O(1)\).}

До \(2.6\) ядра Linux использовался планировщик, который работал за \(O(n)\): мы
проходили по всем процессам и для каждого процесса считали некоторую
характеристику, после чего выбирали процесс с наилучшей характеристикой. В ядре
\(2.6\) появился планировщик, который работает за \(O(1)\). Также отличием этого
планировщика стало то, что он имеет свои системы очередей к каждому ядру, в
отличие от старого планировщика с одной очередью. Как же устроен этот
планировщик?

К каждому ядру есть свой набор из \(140\) пар очередей. Как и в Windows, они
разбиты на два класса: с \(1\)-ой по \(100\)-ую это процессы реального времени,
а со \(101\)-ой по \(140\)-ую это пользовательские (или динамические) процессы.
В отличие от Windows, в Linux более приоритетными являются очереди с меньшим
номером. Внутри второго (пользовательского) класса процессов пользователь может
свободно менять приоритеты. Для это существуют показатель \texttt{nice}, который
принимает значения от \(-20\) до \(+19\), где значению \(-20\) соответствует
\(101\)-ая очередь, а значению \(+19\)~--- последняя, \(140\)-ая очередь.

В рамках одной очереди очередность определяется с помощью аналога FIFO, но при
этом каждому процессу предоставляется некоторый квант непрерывного исполнения,
который зависит от номера очереди: в \(101\)-ой очереди он будет равен
\(200\)~мс, а в \(140\)-ой~--- всего \(10\)~мс. Если в течении этого кванта
процесс успел уйти в ожидание, то когда он вернется из ожидания, то встанет в
конец той же очереди с оставшимся квантом времени исполнения. Если же он не ушел
в ожидание за отведенный ему квант, то он перемещается в парную очередь (как мы
помним в Linux \(140\) \textit{пар} очередей). Набор из \(140\) очередей,
который мы сейчас обрабатываем, называется активным (active), а набор из \(140\)
парных очередей, в которые мы убираем не ушедшие в ожидание процессы, называется
неактивным (non-active). Стоит отметить, что когда мы убираем процесс реального
времени в парную очередь, то он гарантированно попадает в очередь с тем же
приоритетом, а вот пользовательский процесс может попасть в другую очередь
(изменение приоритета может быть от \(-5\) до \(+5\), но перейти в класс
realtime процессов все равно нельзя) в зависимости от вычисленного значения
интерактивности.

Преимущество такого подхода заключается в том, что мы избавляемся от голодания:
постепенно разбирая очереди из процессов, мы так или иначе дойдем до \(140\)-ой
очереди и предоставим процессам в ней время на исполнение. Причем это время
будет меньше, чем время для высокоприоритетных процессов. В более поздних
версиях этого планировщика появился механизм, благодаря которому
высокоприоритетные интерактивные процессы после своего кванта исполнения могут
попасть не в парную очередь, а в конец текущей очереди. Для оценки такой
возможности вводится еще один параметр, который показывает, не будут ли
остальные процессы ждать слишком долго из-за того, что мы позволили какому-то
процессу выполняться дважды. Так или иначе, даже учитывая эту возможность, в
какой-то момент все активные очереди будут разобраны. В этот момент произойдет
обмен: активные очереди станут неактивными, а неактивные~--- активными. Таким
образом новые неактивные очереди будут пустыми, а в новых активных очередях
будут находится процессы, готовые к исполнению.

Для быстрого поиска очереди, в которой есть хотя бы один процесс, используется
битовый вектор. Отсюда и название \(O(1)\), потому что этот поиск происходит за
константу. Однако стоит помнить о том, что для обеспечения эффективного
использования ресурсов, нам необходимо вычислять коэффициент интерактивности,
который является вещественным числом. Так же нам необходимо выполнить разные
дополнительные проверки и вычисления после того, как процесс отработал свой
квант времени. Это и стало причиной критики данного планировщика.

Перед тем, как перейти к другому планировщику, обратим внимание на еще один
момент. Когда процесс порождает новый поток, то он попадает в ту же очередь, что
и его родитель. Из-за этого может возникнуть ситуация, в которой
высокоприоритетный процесс постоянно порождает много потоков, а
низкоприоритетные процессы в это время голодают. Для решения этой проблемы было
придумано следующее решение: когда процесс порождает новый поток, он делит свое
оставшееся время исполнения с этим потоком. Таким образом, сколько бы потоков не
породил процесс, они суммарно будут исполняться не больше, чем изначальный квант
времени, выделенный процессу.

\subheader{Планирование в Linux. Планировщик CFS.}

CFS расшифровывается как Completely Fair Scheduler (абсолютно справедливый
планировщик). Изначально у абсолютно справедливого планирования была проблема с
тем, что коэффициент справедливости это вещественное число, и упорядочивать
процессы по вещественному числу это слишком затратно. Однако с развитием этой
идее появилось следующее предложение: для каждого процесса мы вводим две
величины~--- время исполнения (\exectime) и максимальное время исполнения
(\maxexectime). Далее мы выбираем процесс с наименьшим временем исполнения и
даем ему возможность исполняться время, равное \maxexectime. Если он уйдет в
ожидание, то после возвращения, мы позволим ему выполняться в течении оставшейся
части предоставленного ему времени. Когда процесс потратит весь свой
\maxexectime, то мы вставим его в очередь процессов в соответствии с его новым
\exectime.

Для внешнего управления приоритетами мы можем менять то, как вычисляется
\maxexectime. Изначально он вычисляется как время ожидания поделенное на
количество процессов. Однако при помощи параметра nice (который остался ровно
таким же ради совместимости) мы можем домножать \maxexectime на некоторое
значение, тем самым давая больше времени более приоритетным процессам. Итого мы
сортируем процессы уже по целочисленной переменной \exectime, что уже лучше чем
в изначальной идее справедливого планирования. Казалось бы, асимптотика все
равно останется равной \(O(n)\), т.к. мы вынуждены искать место, в которое нужно
вставить отработавший процесс. Однако если представить очередь в виде
красно-черного дерева, то такая вставка будет работать за \(O(\log n)\). Если
вдобавок к этому хранить указатель на самый левый элемент дерева, то мы всегда
за \(O(1)\) сможем узнать, какой процесс необходимо сейчас выполнять. Итого
получается довольно удобный подход, в котором не нужно долго и сложно считать
интерактивность и разбираться с очередями.

Напоследок несколько слов про многопроцессорность и кэши в рамках планирования в
Linux. У обоих рассмотренных планировщиков к каждому ядру существует своя
очередь, однако раз в некоторый промежуток времени (\(\approx 200\)~мс)
происходит перебалансировка процессов между процессорами. Также отдельно в CFS
вводится такой параметр как гранулированность~--- это специальная величина,
определяющая нижнюю границу для \maxexectime{} (чтобы не было слишком частых
переключений между процессами). Помимо этого нужно сказать, что многие
параметры планирования в Linux, о которых мы упомянули, можно менять, тем самым
настраивания планировщик под конкретную задачу или специфику работы.
