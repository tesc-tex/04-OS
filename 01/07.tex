\subsection{%
  Лекция \texttt{24.??.??}.%
}

\subsubheader{Параметры планирования}{}

\begin{enumerate}
\item
  Статические параметры системы.

  К ним относятся предельные значения имеющихся ресурсов: количество доступных
  ядер, максимально доступный объем памяти и т.д.

\item
  Динамические параметры системы.

  К ним относятся доступные на текущей момент ресурсы: сколько сейчас свободно
  оперативной памяти, какая в среднем нагрузка на ЦП (например, за последние
  несколько минут) и т.д.

\item
  Статические параметры процесса.

  У каждого процесса есть собственные ограничения. К ним относятся, например,
  ограничения, связанные с правами доступа. Допустим, мы знаем, что у процесса
  нет прав на доступ к определенному устройству, а значит он никогда не сможет
  попасть в очередь к этому устройству. Мы можем учесть это при планировании.
  Помимо это у процесса есть \quote{важность}, которая также влияет на
  планирование.

\item
  Динамические параметры процесса.

  Они описывают то, как процесс использует ресурсы. К этой категории относится,
  например, CPU-burst~--- это то, сколько времени будет исполняться процесс до
  того момента, как он либо завершится, либо уйдет в ожидание, при условии, что
  мы дадим ему возможность выполняться на ЦП без прерываний. Ясно, что CPU-burst
  это всегда эвристика, потому что точное значение определить мы не можем. Также
  к этой категории относится IO-burst. Допустим, что процесс выполнил какие-то
  вычисления и ушел в ожидание ввода-вывода. Время, которое он будет там
  находится, и называется IO-burst. Как и в случае с CPU-burst мы не можем
  узнать точное значение этого параметра, а лишь можем дать ему примерную
  оценку.
\end{enumerate}

\subheader{Алгоритмы планирования}

Алгоритмы планирования можно разделить на два больших класса, а именно:
вытесняющее и не вытесняющее планирование. В случае не вытесняющего планирования
если мы дали процессу выполняться, то он только сам может приостановить или
завершить свое исполнение. А в случае вытесняющего планирования мы имеем
некоторый механизм, который позволит нам прервать выполнение текущего процесса
для того, чтобы передать ресурс процессора следующему процессу. Этот механизм
может быть разным: прерывание по таймеру, прерывание из-за появления более
приоритетного процесса и т.д.

Для сравнение эффективности алгоритмов планирования мы будем использовать
следующие показатели:

\begin{enumerate}
\item
 \(\timefull\)~--- полное время исполнения всех процессов, от начала исполнения
 первого процесса до конца исполнения последнего.

\item
  \(\timeexec\)~--- среднее время исполнения. Для каждого процесса сложим время,
  которое он действительно исполнялся, и время, в течение которого он был готов
  исполняться, но находился в состоянии ожидания. Теперь найдем среднее значение
  такой величины для всех процессов~--- это и будет среднее время исполнения.

\item
  \(\timewait\)~--- среднее время ожидания.
\end{enumerate}

\subsubheader{I.}{First Came First Served (FCFS)}

Из названия алгоритма понятно, что он предполагает выполнение процесс в том
порядке, в котором они появлялись.

\galleryone{01_07_01}{FCFS: \(0 \to 1 \to 2\)}

\begin{example} \label{ex:fcfs-bad}
  Пусть у нас три процесса и известны их CPU-burst: \(p_0 = 13\), \(p_1 = 4\) и
  \(p_2 = 1\). Значения приведены в условных единицах, т.к. в данном примере нам
  не очень важны именно единицы измерения. Допустим, что мы будем обслуживать
  процессы в порядке \(0 \to 1 \to 2\). Тогда процесс их исполнения можно
  проиллюстрировать как показано на \figref{01_07_01}. Вычислим характеристики
  для этого случая:

  \begin{equation*}
    \timefull = 18
    \qquad
    \timeexec = \frac{13 + 17 + 18}{3} = 16
    \qquad
    \timewait = \frac{0 + 13 + 17}{3} = 10
  \end{equation*}
\end{example}

\begin{example} \label{ex:fcfs-good}
  А теперь представим, что процессы были расположены в порядке \(2 \to 1 \to
  0\) (см. \figref{01_07_02}) и еще раз вычислим характеристики.

  \begin{equation*}
    \timefull = 18
    \qquad
    \timeexec = \frac{1 + 5 + 18}{3} = 8
    \qquad
    \timewait = \frac{0 + 1 + 5}{3} = 2
  \end{equation*}
\end{example}

Несмотря на то, что общее время исполнения не изменилось (и не могло
измениться), ясно второй вариант будет лучше, потому что ожидающие процессы
также используют ресурсы: например, они занимают место в оперативной памяти.
Таким образом, если процессы меньше ждут, то оперативная память освобождается
быстрее, а значит мы быстрее сможем использовать ее для других задач.

\galleryone{01_07_02}{FCFS: \(2 \to 1 \to 0\)}

Исходя из этих примеров может показаться, что логично всегда \quote{пропускать}
маленькие процессы вперед. Однако это не так: пусть у нас есть некоторый большой
процесс, который пропустил несколько маленьких процессов. Пока маленькие
процессы исполнялись, появились новые маленькие процессы~--- возникает вопрос,
что с ними делать? Если постоянно пропускать процессы вперед очереди, то большой
процесс будет ждать очень долго (а в худшем случае до него очередь так и не
дойдет).

\subsubheader{II.}{Round Robin (RR)}

Предыдущий алгоритм был не вытесняющим~--- а теперь давайте рассмотрим его
вытесняющую версию. Идея заключается в том, что мы выбираем некоторый отрезок
времени, и по очереди даем всем процессам выполняться выбранное количество
времени.

\galleryone{01_07_03}{RR: \(0 \to 1 \to 2\), \(q = 4\)}

\begin{example} \label{ex:rr-bad-4}
  Вернемся к предыдущему примеру. Пусть у нас все также есть три процесса с
  известными CPU-burst: \(p_0 = 13\), \(p_1 = 4\) и \(p_2 = 1\). Сначала
  рассмотрим порядок выполнения \(0 \to 1 \to 2\) при кванте исполнения \(q =
  4\) (\figref{01_07_03}) и вычислим характеристики.
  
  \begin{equation*}
    \timefull = 18
    \qquad
    \timeexec = \frac{18 + 8 + 9}{3} \approx 11.6
    \qquad
    \timewait = \frac{5 + 4 + 8}{3} \approx 5.6
  \end{equation*}
\end{example}

Можно заметить, что несмотря на то, что мы выбрали \quote{плохой} порядок
процессов, итоговые характеристики получились все равно лучше, чем в
\ref{ex:fcfs-bad}. При этом важно отметить, что если бы мы выбрали
\quote{хороший} порядок процессов (\(2 \to 1 \to 0\)), то получили бы такой же
результат, что и в \ref{ex:fcfs-good} (не будем это отдельно иллюстрировать,
т.к. там будет полностью такая же ситуация и характеристики).

\begin{example} \label{ex:rr-bad-1}
  А теперь попробуем уменьшить квант исполнения до \(q = 1\) и посмотрим, что из
  этого выйдет (\figref{01_07_04}). Вычислим характеристики.

  \begin{equation*}
    \timefull = 18
    \qquad
    \timeexec = \frac{18 + 9 + 3}{3} = 10
    \qquad
    \timewait = \frac{5 + 5 + 2}{3} = 4
  \end{equation*}
\end{example}

\galleryone{01_07_04}{RR: \(0 \to 1 \to 2\), \(q = 1\)}

Казалось бы, что из примера следует, что чем меньше квант исполнения, тем ближе
наше распределение времени ЦП к идеальному, однако это не совсем так. Дело в
том, что переключение между процессами не мгновенное: необходимо сохранить
контекст одного процесса, загрузить контекст другого, обновить статусы процессов
и т.д. Таким образом в FCFS мы выполняем всего два переключения между процессами
(меньше просто не получится), а вот в RR переключений становится уже больше:
\(3\) при \(q = 4\) и целых \(9\) при \(q = 1\).

Итого, если схематично изобразить график зависимости реального времени
исполнения от величины кванта, то получится некоторая парабола, ветви которой
направлены вверх. Понятное дело, что при бесконечно большом кванте мы фактически
получаем FCFS (который как мы уже видели в \ref{ex:fcfs-bad} не идеален), а при
кванте бесконечно близком к нулю оптимального решения мы не получим, т.к. будем
иметь слишком большие накладные расходы на переключение между процессами. Значит
задача поиска оптимального кванта времени это тоже отдельная задача оптимизации,
причем решение это задачи сильно зависит от CPU-burst процессов, которые хотят
исполняться. Однако динамически вычислять квант это слишком дорого: мы потратим
много времени на вычисление, а ситуация быстро изменится и наши вычисления
станут неактуальными.

\subsubheader{III.}{Shortest job first (SJF)}

Этот алгоритм существует в вытесняющем и не вытесняющем вариантах, однако чаще
всего используется именно вытесняющий вариант, в котором через некоторые кванты
времени происходит проверка на существование более приоритетного процесса.

\galleryone{01_07_05}{SJF}

\begin{example}
  Пусть у нас есть четыре процесса с известными CPU-burst: \(p_0 = 6\), \(p_1 =
  2\), \(p_2 = 7\) и \(p_3 = 5\). Для наглядности они стартуют не одновременно,
  а с задержкой: \(t_0 = 0\), \(t_1 = 2\), \(t_2 = 6\) и \(t_3 = 0\).
  Проиллюстрируем то, как будут исполняться процессы в этом случае
  (\figref{01_07_05}).
\end{example}

Как мы видим этот алгоритм (в вытесняющем варианте) объединяет в себе идею
предыдущего алгоритма и упорядочивание очереди по возрастанию. Однако здесь мы
снова возвращаемся к тому, что если всегда пропускать маленькие процессы вперед,
то до больших процессов очередь может просто не дойти. Про такие процессы
говорят, что они находится в состоянии \quote{голодания}, т.е. они готовы
исполняться, но ОС не предоставляет им право на исполнение, и они висят в
ожидании.

\subsubheader{IV.}{Гарантированное планирование}

Обозначим \(N\)~--- количество процессов в системе, \(T_i\)~--- время сеанса
\(i\)-ого процесса (т.е. время с момента его готовности до текущего момента), а
\(\tau_i\)~--- время исполнения \(i\)-ого процесса (сколько времени мы давали
этому процессу исполняться).

Если предыдущие алгоритмы действовали с позиции эффективности, то этот алгоритм
действует с позиции справедливости, а именно: мы хотим, чтобы выполнялось
\(\tau_i \sim \frac{T_i}{N}\). Если мы вычислим отношение этих двух величин

\begin{equation*}
  R_i = \frac{\tau_i}{T_i} \cdot N
\end{equation*}

то получим коэффициент \(R_i\), который называется коэффициентом справедливости
(для \(i\)-ого процесса). Далее если мы возьмем процесс с наименьшим
коэффициентом справедливости (т.е. процесс, который мы больше всего
\quote{обделили}) и дадим ему исполняться, то его коэффициент справедливости
будет увеличиваться, в то время как коэффициент справедливости других процессов
будет уменьшаться (т.к. у них будет расти знаменатель, а числитель будет
оставаться таким же). Таким образом через некоторое время самый
\quote{обделенный} процесс перестанет быть таковым, и его место займет другой
процесс.

Итого алгоритм заключается в том, что мы берем процесс с наименьшим
коэффициентом справедливости и даем ему исполняться в течении некоторого кванта
времени. Далее мы прерываем этот процесс, снова находим процесс с наименьшим
коэффициентом справедливости, предоставляем ему возможность исполнятся и так по
кругу. Таким образом мы повысим справедливости распределения времени, но
потеряем в эффективности. Однако у этого алгоритма есть и другие проблемы.
Первая из них заключается в накладных расходах: вычислять коэффициенты
справедливости, являющиеся вещественными числами, а потом еще и сравнивать их
для поиска наименьшего это недешевая операция (особенно учитывая то, что делать
это нужно весьма часто). Второй проблемой является неустойчивость ко
\quote{взлому}: можно сделать так, что процесс будет запущен, но не будет
требовать времени исполнения, а будет просто ничего не делать. Потом, когда
время его сеанса \(T_i\) возрастет достаточно, он начнет свои вычисления, причем
из-за большого \(T_i\), которое он накопил, данный процесс будет получать
приоритет и фактически на время своего исполнения полностью вытеснит все
остальные процессы.

\subsubheader{V.}{Многоуровневые очереди}

Во всех предыдущих алгоритмах мы использовали некоторый программно вычисляемый
приоритет: в SJF это был CPU-burst (мы всегда выбирали процесс с наименьшим
CPU-burst), при гарантированном планирование это был коэффициент справедливости
(опять же, мы выбирали процесс с наименьшем коэффициентом справедливости). А что
если приоритет будет задаваться извне? Допустим, при создании каждого процесса
пользователь будет сопоставлять ему некоторое целое число, которое мы будем
считать приоритетом этого процесса. Здесь сразу же возникает проблема с
дискретностью шкалы приоритетов: пусть у меня есть процессы с приоритетами \(2\)
и \(3\). Я хочу создать процесс, приоритет которого будет меньше, чем у
первого процесса, но больше, чем у второго. Однако я не могу сделать приоритет
\(2.5\) в силу того, что приоритет это целое число.

Эту проблему можно попытаться решить следующим образом: пусть мы изначально
будем выдавать приоритеты с шагом в (например) \(10\), а потом если потребуется,
то будем выдавать промежуточные приоритеты, например \(25\) или \(22\) и т.д.
Однако это не решает проблему полностью: все равно в какой-то момент мы упремся
в то, что захотим выдать приоритет, который не будет являться целым числом.
Делать приоритет не целым числом мы не хотим, т.к. работа с нецелыми числами
будет иметь повышенные накладные расходы. К тому же, если вдруг возникнет два
процесса с одинаковым приоритетом, то какой из них нужно выбрать? Получается,
что нужно вводить некоторые дополнительные правила.

Вместо этого была предложена следующая идея: пусть мы изначально зададим
некоторый фиксированный набор приоритетов (например от \(1\) до \(P\)), который
можно выдать процессу, и позволим нескольким процессам иметь одинаковый
приоритет. Таким образом для каждого значения приоритета сформируется своя
очередь. Мы будем поступать следующим образом: сначала выполним все процессы
с первым приоритетом, потом все процессы со вторым приоритетом и т.д. Если в
какой-то момент появляется новый процесс с более высоким приоритетом, чем
исполняемый в данный момент, то мы прерываем текущий процесс и переключаемся на
появившийся процесс. Если внутри одного приоритета есть несколько
процессов, то мы используем например Round Robin для того, чтобы определить
очередность выполнения процессов.

Однако у такого похода есть проблема, о которой мы уже говорили. Пусть у нас
есть процесс с самым низким приоритетом. Существует вероятность того, что до
этого процесса выполнение никогда не дойдет, потому что постоянно будут
появляться новые процессы с более высоким приоритетом. Да, они будут
исполняться, но на их место будут приходить все новые и новые процессы. Таким
образом наш процесс будет находиться в состоянии \quote{голодания}. Для того,
чтобы как-то этого избежать, мы можем поступить следующим образом: если процесс
за некоторое заранее отведенное время (timeout) ни разу не получил возможность
исполняться, то мы повышаем его приоритет не единичку. Таким образом мы как бы
создаем \quote{лифт}, благодаря которому низкоприоритетные процессы через
некоторое время смогут повысить свой приоритет и получить возможность
исполняться. После того, как процесс получил свой квант времени исполнения, он
\quote{отбрасывается} в очередь, соответствующую его изначальному приоритету.
После этого он снова вынужден ждать и постепенно повышать свой приоритет, чтобы
вновь получить возможность исполняться.

Итого, низкоприоритетные процессы вынуждены пропорционально больше ждать, чем
высокоприоритетные процессы, но при этом они не голодают и спустя некоторое
время гарантированно получат возможность исполняться. Казалось бы это хорошее
решение, однако у него все еще есть недостатки. Мы разобрались с проблемой
голодания, но не разобрались с проблемой эффективности: если мы изначально
неправильно распределим приоритеты, то общая эффективность нашей системы будет
низкой. Для того, чтобы это исправить, появляется идея многоуровневых очередей с
обратной связью. Пусть мы также имеем несколько очередей и для каждой очереди
выбираем квант непрерывного выполнения, причем очереди с более низким
приоритетом соответствует б\'oльший квант времени. Новорожденный процесс
изначально попадает с первую очередь. Если, когда до него дойдет время, он
успеет выполнится за квант времени, соответствующий этой очереди, то мы оставим
его в ней. Если же он не успеет этого сделать, то мы его прервем и отправим в
очередь с более низким приоритетом. Таким образом, процессы, требующие много
времени исполнения, будут попадать во все более и более низкоприоритетные
очереди, но при этом когда до них дойдет время, то они будут получать все больше
и больше непрерывного времени исполнения.

Такой подход пытается объединить в себе идеи SJF и идеи гарантированного
планирования. Однако у нас остается проблема с голоданием: если процесс попал
в низкоприоритетную очередь, то он, конечно, получит много времени непрерывного
исполнения, когда до него дойдет очередь, но что, если эта очередь никогда до
него не дойдет? С этого момента развитие ОС пошло таким образом, что люди
пытались скомбинировать уже имеющиеся алгоритмы и найти некоторый компромисс в
требованиях, выдвигаемых к этим алгоритмам. Конкретные идеи, реализованные в
разных ОС, будут рассмотрены на следующей лекции.
